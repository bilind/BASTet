

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>HDF5 I/O Performance &mdash; BASTet: Berkeley Analysis and Storage Toolkit Documentation devel documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="BASTet: Berkeley Analysis and Storage Toolkit Documentation devel documentation" href="index.html"/>
        <link rel="next" title="omsi Package" href="omsi.html"/>
        <link rel="prev" title="OMSI Data Format" href="HDF5_format.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="index.html" class="fa fa-home"> BASTet: Berkeley Analysis and Storage Toolkit Documentation</a>
        
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="convert_files.html">Converting Files at NERSC and Making them Accessible</a><ul>
<li class="toctree-l2"><a class="reference internal" href="convert_files.html#making-a-converted-file-accessible-to-openmsi-private">Making a converted file accessible to OpenMSI (Private)</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert_files.html#changing-file-permissions">Changing file permissions:</a></li>
<li class="toctree-l2"><a class="reference internal" href="convert_files.html#converttoomsi-usage-and-options"><code class="docutils literal"><span class="pre">convertToOMSI</span></code>: Usage and Options</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_filereader.html">Integrating new file formats</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_filereader.html#developing-a-file-reader">Developing a file reader</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_filereader.html#integrating-the-file-reader-with-openmsi">Integrating the file reader with OpenMSI</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_analysis.html">Developing a new Analysis for BASTet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_analysis.html#wrapping-a-function-the-quick-and-dirty-way">Wrapping a function: The quick-and-dirty way</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_analysis.html#writing-a-new-analysis-class-for-bastet-part-1-overview">Writing a new analysis class for BASTet &#8211; Part 1: Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_analysis.html#writing-a-new-analysis-class-for-bastet-part-2-analysis-template">Writing a new analysis class for BASTet &#8211; Part 2: Analysis Template</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_analysis.html#writing-a-new-analysis-class-for-bastet-part-3-customizing-core-features">Writing a new analysis class for BASTet &#8211; Part 3: Customizing core features</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="basic_workflows.html">Defining and Executing Analysis Workflows</a><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_workflows.html#step-1-create-the-analysis-tasks">Step 1: Create the analysis tasks:</a></li>
<li class="toctree-l2"><a class="reference internal" href="basic_workflows.html#step-2-define-analysis-inputs">Step 2: Define analysis inputs:</a></li>
<li class="toctree-l2"><a class="reference internal" href="basic_workflows.html#step-3-execute">Step 3: Execute</a></li>
<li class="toctree-l2"><a class="reference internal" href="basic_workflows.html#example-normalizing-an-image">Example: Normalizing an image</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="basic_workflows.html#workflow-tools">Workflow Tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_workflows.html#workflow-scripts">Workflow Scripts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developer_notes.html">Developer Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="developer_notes.html#building-the-online-documentation">Building the online documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="HDF5_format.html">OMSI Data Format</a><ul>
<li class="toctree-l2"><a class="reference internal" href="HDF5_format.html#data-layout">Data Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="HDF5_format.html#accessing-omsi-data-files">Accessing OMSI data files</a></li>
<li class="toctree-l2"><a class="reference internal" href="HDF5_format.html#convert-mass-spectrometry-imaging-data-to-omsi-hdf5-format">Convert Mass Spectrometry Imaging Data to OMSI (HDF5) format</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">HDF5 I/O Performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#test-platforms">Test Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#test-cases">Test Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dataset-layout">Dataset Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chunking-part-1">Chunking: Part 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chunking-part-2">Chunking: Part 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compression">Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#local-scalability-multi-processing">Local Scalability: Multi-processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="omsi.html">omsi Package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omsi.html#subpackages">Subpackages</a></li>
</ul>
</li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">BASTet: Berkeley Analysis and Storage Toolkit Documentation</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>HDF5 I/O Performance</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/HDF5_format_performance.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="hdf5-i-o-performance">
<h1>HDF5 I/O Performance<a class="headerlink" href="#hdf5-i-o-performance" title="Permalink to this headline">Â¶</a></h1>
<p>Analysis and visualization of mass spectrometry imaging (MSI) data is often based on selected subsets of the data, e.g., single or multiple spectra or m/z data slices. It is, therefore, crucial that we are able to quickly access select subsets of the data. In the context of web-based applications &#8212;such as the OpenMSI Viewer&#8212; this is particularly crucial in order to enable interactive data analysis and to provide a satisfactory user experience. The tests described here focus on characterizing and optimizing the performance of data access operations performed in serial on OMSI HDF5 files. While we here focus on the performance of serial data accesses, the optimizations described here are fundamental to optimizing parallel data access as well.</p>
<p>In the following, we first identify a select set of target compute platforms (Section <a class="reference internal" href="#hdf5-test-platforms"><span>Test Platforms</span></a>) and define a set of representative use cases in order to evaluate the performance of different data layouts (Section <a class="reference internal" href="#hdf5-test-cases"><span>Test Cases</span></a>). We then discuss the basic layout of the MSI data (Section <a class="reference internal" href="#hdf5-test-data-layout"><span>Dataset Layout</span></a>) and establish the baseline performance using the default contiguous data layout (Section <a class="reference internal" href="#hdf5-test-baseline"><span>Baseline Performance</span></a>). Afterwards, we  explore further optimization of the data layout using HDF5&#8217;s data chunking (Section <a class="reference internal" href="#hdf5-test-chunking"><span>Chunking: Part 1</span></a>) and data compression (Section <a class="reference internal" href="#hdf5-test-compress"><span>Compression</span></a>) capabilities. We conclude this study with a discussion of lessons-learned in Section <a class="reference internal" href="#hdf5-test-discussion"><span>Discussion</span></a>.</p>
<div class="section" id="test-platforms">
<span id="hdf5-test-platforms"></span><h2>Test Platforms<a class="headerlink" href="#test-platforms" title="Permalink to this headline">Â¶</a></h2>
<p>All tests were performed on two main compute systems: i) login node of <code class="docutils literal"><span class="pre">hopper.nersc.gov</span></code> (short <code class="docutils literal"><span class="pre">hopper</span></code>) and ii) <code class="docutils literal"><span class="pre">portal-auth.nersc.gov</span></code> (short <code class="docutils literal"><span class="pre">portal</span></code>). On <code class="docutils literal"><span class="pre">hopper</span></code> we utilized the LUSTRE-based <code class="docutils literal"><span class="pre">/scratch</span></code> file system, as well as the global GPFS-based <code class="docutils literal"><span class="pre">/project</span></code> file system. On <code class="docutils literal"><span class="pre">portal</span></code> we can only access the <code class="docutils literal"><span class="pre">/project</span></code> file system. We chose these systems because: i) <code class="docutils literal"><span class="pre">hopper</span></code> is our candidate system for performing large-scale parallel analysis of MSI data and ii) <code class="docutils literal"><span class="pre">portal</span></code> is our target system for providing web-based access to MSI data.</p>
<div class="section" id="hopper-nersc-gov">
<h3><code class="docutils literal"><span class="pre">hopper.nersc.gov</span></code><a class="headerlink" href="#hopper-nersc-gov" title="Permalink to this headline">Â¶</a></h3>
<p>The <code class="docutils literal"><span class="pre">hopper</span></code> system has 12 login nodes with 4 quad-core AMD 2.4 GHz Opteron 8378 processors (16  cores total) each on 8 of the login nodes and 4 8-core AMD 2.0 GHz Opteron 6128 processors (32 cores total) each on 4 of the login nodes. Each login node has 128 GB of memory. The login nodes are external to the main Cray XE6 system. All tests were performed using <code class="docutils literal"><span class="pre">hopper</span></code> login nodes.</p>
<p><strong>Scratch:</strong> There are two Lustre file systems on <code class="docutils literal"><span class="pre">hopper</span></code> &#8212;mounted as <code class="docutils literal"><span class="pre">/scratch</span></code> and <code class="docutils literal"><span class="pre">/scratch2</span></code> (in the following we use <code class="docutils literal"><span class="pre">/scratch2</span></code>)&#8212; with the following setup:</p>
<blockquote>
<div><ul class="simple">
<li>13 LSI 7900 disk controllers (Each disk controller is served by 2 I/O Object Storage Servers (OSSs))</li>
<li>Each OSS host 6 OSTs (Object Storage Target) (simplified speaking a software abstraction of a physical disk)</li>
<li>Fiber Channel 8 connectivity from OSSs to the LSI disk controllers</li>
<li>Infiniband connects the Lustre router nodes in the 3d torus through a QDR switch to the OSSs</li>
<li>In total each <code class="docutils literal"><span class="pre">/scratch</span></code> file system has 156 OSTs which is the lowest layer with which users need to interact.  When a file is created in <code class="docutils literal"><span class="pre">/scratch</span></code> it is by default &#8220;striped&#8221; or split across two different OSTs. Striping is a technique to increase I/O performance.  Instead of writing to a single disk, striping to two disks allows the user to potentially double read and write bandwidth. In the following experiments we use the default stripping settings but depending on file size, larger stripe settings may be advantageous. Using the <code class="docutils literal"><span class="pre">/scratch</span></code> file system for temporary storage of MSI data files can be advantageous when performing complex I/O intensive analysis.</li>
</ul>
</div></blockquote>
<p><strong>Global</strong> <code class="docutils literal"><span class="pre">/project</span></code> <strong>:</strong> This is a large (1606 TB), permanent, medium-performance GPFS-based file system. We utilized the <code class="docutils literal"><span class="pre">/project</span></code> file system in the context of the OpenMSI project for permanent storage of MSI data.</p>
</div>
<div class="section" id="portal-auth-nersc-gov">
<h3><code class="docutils literal"><span class="pre">portal-auth.nersc.gov</span></code><a class="headerlink" href="#portal-auth-nersc-gov" title="Permalink to this headline">Â¶</a></h3>
<p>The <code class="docutils literal"><span class="pre">portal</span></code> system is used at NERSC for any data services that require public access from the Internet (such as Science Gateways) and as such also hosts the OpenMSI webpage and science gateway. The system consists of 2 quad-core AMD Opteron 2378 processors (8 cores total) with 24GB of memory. This system has only access to the <code class="docutils literal"><span class="pre">/project</span></code> file system.</p>
</div>
</div>
<div class="section" id="test-cases">
<span id="hdf5-test-cases"></span><h2>Test Cases<a class="headerlink" href="#test-cases" title="Permalink to this headline">Â¶</a></h2>
<p>In order to evaluate the performance of different data layouts, we designed a set of test-cases modeling the most common data access patterns in the analysis of MSI data. One particular focus of this study is to optimize the performance of the file format for web-based access to the data required for OpenMSI&#8217;s online data viewing, analysis and exploration functionality. In this context it is most important that we are able to quickly access select subsets of the data, in particular, image slices, spectra or subcubes of the data. These type of data access patterns, however, are very common also for a large range of data analyses, e.g., peak finding on individual spectra, data clustering and many others. In contrast to analysis performed with direct access to the compute system, the abilities for data caching are typically much more limited in a web-based setting due to the fact that: i) http accesses are stateless, i.e., a file is typically reopend for each incoming request and closed again afterwards and ii) access patterns to the data are much more irregular with multiple users working with different datasets and/or different subsets of the data at the same time. While the median performance for repeated data selection operations on the same open file is often very important for data analysis, in a web-based setting the maximum time for the first access to the data is often much more important. In the following we report for each selection test case the median time (indicating the sustained performance on an open file) and the maximum time (indicating the selection performance after the first opening of the file). We usually repeat each selection test case 50 times for each data layout using randomized selection parameters.</p>
<div class="section" id="case-1-m-z-slice-selection">
<h3>Case 1: m/z Slice Selection<a class="headerlink" href="#case-1-m-z-slice-selection" title="Permalink to this headline">Â¶</a></h3>
<p>This test case models the selection of a series of z-slices of the data (i.e., slices in a mass range), and extracts a set of consecutive, full images of the data. This type of operation is required in the OpenMSI viewer when updating channels in the image viewer itself. It is also a common operation in many other analyses, e.g, when analyzing the distribution for a particular peak across the image.</p>
<ul class="simple">
<li><strong>Randomized Selection Parameters:</strong> <code class="docutils literal"><span class="pre">zmin</span></code></li>
<li><strong>Dependent Selection Parameters:</strong> <code class="docutils literal"><span class="pre">zmax</span> <span class="pre">=</span> <span class="pre">zmin+25</span></code></li>
<li><strong>Extracted Dataset:</strong> <img class="math" src="_images/math/9658956ee5cd635a8f669789c59502f0daaa42e8.png" alt="100 \times 100 \times 25 = 250,000 \text{ records} = 500,000 \text{ bytes} = 0.5 \text{MB}"/></li>
</ul>
</div>
<div class="section" id="case-2-spectra-selection">
<h3>Case 2: Spectra Selection<a class="headerlink" href="#case-2-spectra-selection" title="Permalink to this headline">Â¶</a></h3>
<p>This test case models the selection of a <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> set of full spectra. In the OpenMSI viewer, access to single and multiple neighboring spectra is required when updating the spectrum plot&#8217;s. This is also a typical operation for many analyses that operate on a per spectrum basis, e.g., peak finding for a single spectrum.</p>
<ul class="simple">
<li><strong>Randomized Selection Parameters:</strong> <code class="docutils literal"><span class="pre">xmin</span></code> , <code class="docutils literal"><span class="pre">ymin</span></code></li>
<li><strong>Dependent Selection Parameters:</strong> <code class="docutils literal"><span class="pre">xmax</span> <span class="pre">=</span> <span class="pre">xmin+5</span></code> , <code class="docutils literal"><span class="pre">ymax</span> <span class="pre">=</span> <span class="pre">ymin+5</span></code></li>
<li><strong>Extracted Dataset:</strong> <img class="math" src="_images/math/673d5b2d4927ab4d830baf47fcad25609e6b1283.png" alt="5 \times 5 \times 100,000 = 200,000 \text{ records} = 2,500,000 \text{ bytes} = 5 \text{MB}"/></li>
</ul>
</div>
<div class="section" id="case-3-3d-subcube-selection">
<h3>Case 3: 3D Subcube Selection<a class="headerlink" href="#case-3-3d-subcube-selection" title="Permalink to this headline">Â¶</a></h3>
<p>This selection models the general access to consecutive sub-pieces of the data, e.g., when accessing data from a particular spatial region of the data related to a particular set of m/z data values. This type of operation is required, e.g., when analyzing the data of a cluster of pixels with a particular set of peaks of interest.</p>
<ul class="simple">
<li><strong>Randomized Selection Parameters:</strong> <code class="docutils literal"><span class="pre">xmin</span></code> , <code class="docutils literal"><span class="pre">ymin</span></code>, <code class="docutils literal"><span class="pre">zmin</span></code></li>
<li><strong>Dependent Selection Parameters:</strong> <code class="docutils literal"><span class="pre">xmax</span> <span class="pre">=</span> <span class="pre">xmin+5</span></code> , <code class="docutils literal"><span class="pre">ymax</span> <span class="pre">=</span> <span class="pre">ymin+5</span></code>, <code class="docutils literal"><span class="pre">zmax</span> <span class="pre">=</span> <span class="pre">zmin+1000</span></code></li>
<li><strong>Extracted Dataset:</strong> <img class="math" src="_images/math/5df9920cbac52d889e93d74673b18fff2c949ab1.png" alt="5 \times 5 \times 1,000 = 25,000 \text{ records} = 50,000 \text{ bytes} = 0.05 \text{ MB}"/></li>
</ul>
</div>
<div class="section" id="case-4-data-write">
<h3>Case 4: Data Write<a class="headerlink" href="#case-4-data-write" title="Permalink to this headline">Â¶</a></h3>
<p>As described above, the aim of this study is to optimize the performance of selective data read operations (termed hyperslap selections in HDF5). In contrast to the data read, data write is a one-time cost during the file conversion step and is, therefore, less critical to the operation of OpenMSI. A reduced write performance may, therefore, be acceptable in lieu of an increase in read performance as long as an acceptable write performance is maintained. During selection performance tests, the data write is repeated only 3 times for each data layout (i.e.,once for each of the three selection test cases). For selected cases (indicated in the plot titles) we ran dedicated data write tests with 10 repeats. We here typically report the average times for data write.</p>
</div>
<div class="section" id="case-5-file-size">
<h3>Case 5: File Size<a class="headerlink" href="#case-5-file-size" title="Permalink to this headline">Â¶</a></h3>
<p>The size of data files is important to this study as different file layouts may have different space requirements (e.g., due to padding and additional metadata). While reduction of the size of data files is not the main objective of this work, it is important to avoid unnecessary overheads in file size and, hence, storage cost.  The size of files reported in this study have been determined using the Python command <code class="docutils literal"><span class="pre">os.stat(</span> <span class="pre">filename</span> <span class="pre">).st_size</span></code>.</p>
</div>
<div class="section" id="test-data">
<h3>Test Data<a class="headerlink" href="#test-data" title="Permalink to this headline">Â¶</a></h3>
<p>For this study we use a <img class="math" src="_images/math/88b9901484e3098a9105be872600aae61460ba58.png" alt="100 \times 100 \times 100,000"/> test dataset. The dataset is stored as a 3D array of UInt (16bit) data values using the OMSI HDF5 format described in Chapter <a class="reference internal" href="HDF5_format.html#data-format"><span>OMSI Data Format</span></a> . Data write and hyperslap performance are independent of the data values being written/read, so to test the baseline write-performance, we simply assign to each data element the index of the corresponding data chunk. For test cases that utilize data compression, we use a donor MSI data file to fill the file with realistic data. We may replicate data from the donor file in case that the testfile is larger than the donor file. In case that a donor file is used, we read the donor data into memory prior to writing of the test dataset. For each test case (i.e., data layout + selection case) we generate a new test data file to reduce/eliminate effects of data caching. The newly generated file is then opened and the current selection (i.e., hyperslap selection) is repeated 50 times using randomized selection parameters.</p>
<p>Raw data files used in this study are:</p>
<ul>
<li><p class="first"><strong>Dataset A:</strong>  (default donor file)</p>
<blockquote>
<div><ul class="simple">
<li><strong>Name:</strong> 11042008_NIMS.h5</li>
<li><strong>Dimensions:</strong> <img class="math" src="_images/math/aa52604f20f997ce4a59688b2ebc06fb7c7e559f.png" alt="227 \times 108 \times 63,378"/></li>
<li><strong>Raw Data Size:</strong> <img class="math" src="_images/math/c43b42e4a83b605dd9786deb2dad0add65ca7331.png" alt="3.2 \text{GB}"/></li>
<li><strong>File Size:</strong> <img class="math" src="_images/math/fd722387bb21332ba86175e8d92be4a16cb6d225.png" alt="3.3 \text{GB}"/> (including results from global peak finding and nmf)</li>
</ul>
</div></blockquote>
</li>
<li><p class="first"><strong>Dataset B:</strong></p>
<blockquote>
<div><ul class="simple">
<li><strong>Name:</strong> 2012_0403_KBL_platename.h5 (DoubleV)</li>
<li><strong>Dimensions:</strong> <img class="math" src="_images/math/a272e906a4d57f1fdf20989bc43705c6e81e8cb9.png" alt="160 \times 250\times 116,152"/></li>
<li><strong>Raw Data Size:</strong> <img class="math" src="_images/math/d4a5656e8a1a34f3aad83308b9181090a5f07c8b.png" alt="9.3 \text{GB}"/></li>
<li><strong>File Size:</strong> <img class="math" src="_images/math/391e5ce12f7ff90adb060f8c985afe3251e55b6f.png" alt="9.5 \text{GB}"/> (including results from global peak finding and nmf)</li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="dataset-layout">
<span id="hdf5-test-data-layout"></span><h2>Dataset Layout<a class="headerlink" href="#dataset-layout" title="Permalink to this headline">Â¶</a></h2>
<p>A single (2D) MSI dataset defines a 3D data volume with the spatial coordinates <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/>, <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> and the <img class="math" src="_images/math/a5a5aed8b62ac69a185c8345dd49ba766aac705d.png" alt="m/z"/> (mass) as third dimension (<img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/>). In raw block-of-uint format (e.g, in the IMG format) the data is often stored in a 1D linearized fashion: <img class="math" src="_images/math/74fd998eeb7883e7daf18ba33cb2ca9ad495b583.png" alt="{spectrum_{0,0}, \ spectrum_{0,1}, \ ... \ , \ spectrum_{l,m} }"/>. While such a layout is well-suited for accessing single full spectra, access to single image z-slices requires <img class="math" src="_images/math/0ec1d00e9e21174c09698630948e3d555437f5a3.png" alt="l*m"/> seek operations and traversal of the complete dataset (with l, m being the number of pixel in x,y ,respectively). Selection of spectra and z-slices of the data are orthogonal selection operations, i.e., a 1D data layout can always just optimize one of the two access operations but not both. Similarly, a 2D data layout can be defined to enable easy access to full spectra as well as full z-slices, but does not easily support to optimize access to 3D subsets of the data. We, therefore, store MSI data as a 3D array in HDF5 to: i) be be able to optimize and find a good performance compromise for selection of spectra, z-slices as well as 3D subcubes of the data and ii) because the 3D array reflects the true dimensionally of the data.</p>
<p>HDF5 can represent array datasets with as many as 32 dimensions. However, in the file the data is linearized in order to store it as part of the 1-dimensional stream of data that is the low-level file. The data layout determines in which way the multidimensional dataset is mapped to the serial file. The simplest way to accomplish this is to flatten the dataset (similar to how arrays are stored in memory) and to store the entire dataset into a monolithic block on disk. We here use this, so-called, contiguous layout as baseline for our performance tests (see Section <a class="reference internal" href="#hdf5-test-baseline"><span>Baseline Performance</span></a>).</p>
<p>Chunking provides an alternative to the contiguous layout. In contrast to storing the data in a single block in the HDF5 file, using chunking the data is split into multiple chunks. Each chunk of a dataset is allocated separately and stored at independent locations throughout the HDF5 file. The chunks of a dataset can then be read/written independently, enabling independent parallel I/O and potentially improving performance when operating on a subset of the dataset. Data chunks may be stored in arbitrary order and position within the HDF5 file. HDF5 uses a B-tree to map a chunks N-dimensional address to a physical file addresses. The size of the B-tree directly depends on the number of chunks allocated for a dataset. The more chunks are allocated for a dataset:  i) the larger overhead for traversal of the B-tree, ii) the higher the potential contention for the metadata cache, and iii) the larger the number of I/O operations. An introduction to data chunking in HDF5 is provided at <a class="reference external" href="http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/">http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/</a> . The performance of different chunking strategies for storing MSI data is evaluated in Section <a class="reference internal" href="#hdf5-test-chunking"><span>Chunking: Part 1</span></a>.</p>
<p>Use of chunking also enables the use of HDF5 I/O filters. We here investigate the use of compression filters. I/O filters are applied in HDF5 to each chunk individually, and entire chunks are processed at once. I/O filters enabled for a dataset are executed every time a chunk is loaded or flushed to disk. Choosing proper settings for the chunking (and chunk cache) are, therefore, critical for the performance of filtered datasets. The potential use of <code class="docutils literal"><span class="pre">gzip</span></code> compression for improving file size and hyperslap selection of MSI datasets is evaluated in Section <a class="reference internal" href="#hdf5-test-compress"><span>Compression</span></a>.</p>
<p>Chunking and HDF5 I/O filters (e.g., data compression) are implemented transparently in HDF5, i.e, the API functions for reading/writing chunked/compressed datasets are the same ones used to read/write datasets with a uncompressed, contiguous layout. The layout (i.e., chunking scheme and compression options) is defined via a single function call to set up the layout on a property list before the dataset is created.</p>
<div class="section" id="baseline-performance">
<span id="hdf5-test-baseline"></span><h3>Baseline Performance<a class="headerlink" href="#baseline-performance" title="Permalink to this headline">Â¶</a></h3>
<p>The goal of this section is to establish a baseline for the performance of the basic HDF5 contiguous data layout (i.e., without chunking). The baseline performance for the three selection test cases are shown in Figures i) <a class="reference internal" href="#hdf5baselineslice-figure"><span>Baseline performance for the slice selection test case</span></a>, ii) <a class="reference internal" href="#hdf5baselinespectra-figure"><span>Baseline performance for the spectra selection test case</span></a>, and iii) <a class="reference internal" href="#hdf5baselinesubcube-figure"><span>Baseline performance for the subcube selection test</span></a>. The bar plots show the minimum (blue), median (blue+red), average (blue+red+green), and maximum (blue+red+green+lilac) times for retrieving the selected data. We observe that <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code> provides much better performance for selection of spectra and 3D subcubes of the data. For the z-slice selection we observe that <code class="docutils literal"><span class="pre">hopper</span></code> achieves good median and average selection performance, whereas the performance of the z-slice selection on <code class="docutils literal"><span class="pre">portal</span></code> is generally poor. In all cases, we observe poor worst-case (maximum) times for the z-slice selection case.</p>
<p>For serial data write performance we observe that <code class="docutils literal"><span class="pre">/project</span></code> provides better write performance. However, for parallel write operations, the LUSTRE-based <code class="docutils literal"><span class="pre">/scratch</span></code> file system is expected to outperform <code class="docutils literal"><span class="pre">/project</span></code>.</p>
<div class="figure" id="id16">
<span id="hdf5baselineslice-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Baseline_SliceQuery.png"><img alt="Baseline performance for slice selection" src="_images/HDF5_Baseline_SliceQuery.png" style="width: 621.6px; height: 395.5px;" /></a>
<p class="caption"><span class="caption-text">Baseline performance for the slice selection test case</span></p>
</div>
<div class="figure" id="id17">
<span id="hdf5baselinespectra-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Baseline_SpectraQuery.png"><img alt="Baseline performance for spectra selection" src="_images/HDF5_Baseline_SpectraQuery.png" style="width: 590.8px; height: 394.1px;" /></a>
<p class="caption"><span class="caption-text">Baseline performance for the spectra selection test case</span></p>
</div>
<div class="figure" id="id18">
<span id="hdf5baselinesubcube-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Baseline_SubcubeQuery.png"><img alt="Baseline performance for subcube selection" src="_images/HDF5_Baseline_SubcubeQuery.png" style="width: 560.7px; height: 392.7px;" /></a>
<p class="caption"><span class="caption-text">Baseline performance for the subcube selection test</span></p>
</div>
<div class="figure" id="id19">
<span id="hdf5baselinewrite-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Baseline_Write.png"><img alt="Baseline performance for data write" src="_images/HDF5_Baseline_Write.png" style="width: 636.3px; height: 378.0px;" /></a>
<p class="caption"><span class="caption-text">Baseline performance for data write</span></p>
</div>
</div>
</div>
<div class="section" id="chunking-part-1">
<span id="hdf5-test-chunking"></span><h2>Chunking: Part 1<a class="headerlink" href="#chunking-part-1" title="Permalink to this headline">Â¶</a></h2>
<p>Use of a chunked data layout has many potential advantages. In particular, use of chunking enables independent data I/O operations on individual chunks of the data so that chunking: i) can reduce the amount of data that needs to be read during hyperslab selections, ii) enables parallel independent I/O on a single file, and iii) enables the use of data compression (discussed later in Section <a class="reference internal" href="#hdf5-test-compress"><span>Compression</span></a>). The goal of this section is to evaluate the use of chunking to improve I/O performance. Due to the amount of additional metadata and overhead associated with finding chunks, one should avoid the use of too small chunks. At the same time, use of too large chunks should be avoided, because the entire chunk must be read from disk (and decompressed) before performing any operations. When operating on small subsets of the data (and if the cache is too small to hold the chunk), the use of too large chunks can result in large performance penalties. In addition, if the chunk is too large to be held in memory, the operating system may have to page memory to disk, slowing down the entire system. <a class="footnote-reference" href="#fc1" id="id1">[1]</a></p>
<p>Choosing a good chunking strategy for MSI data is complicated because: i) the data has a very unconventional shape, with the m/z dimension being three to four orders of magnitude larger than the spatial x/y dimensions and ii) orthogonal data access operations (access to spectra vs. z-slices) are required with good first-time-access performance.</p>
<p>To account for these properties we use odd chunk sizes of <img class="math" src="_images/math/da74985ed767098a98e4c6bae0a872ed7674f13b.png" alt="m \times m \times n"/> with <img class="math" src="_images/math/84b73245f32774cf78a44563a1039e9fa4d4c9d3.png" alt="n &gt;&gt; m"/>. Finding a good compromise for choosing a good chunking is challenging. Larger chunk sizes <img class="math" src="_images/math/c4bb40dd65eae6c11b325989b14e0b8d35e4e3ef.png" alt="m"/> in x, y are expected to improve z-slice selections but also increase the overhead for spectra selections. Similarly, large chunk sizes <img class="math" src="_images/math/413f8a8e40062a9090d9d50b88bc7b551b314c26.png" alt="n"/> in z (m/z) are expected to improve spectra selections while increasing the overhead for z-slice selections. The goal of this first set of experiments is to find a chunking that provides a good compromise in performance for all three selection test cases.</p>
<p>In the following we compare the performance of a range of different chunking strategies of the form <img class="math" src="_images/math/da74985ed767098a98e4c6bae0a872ed7674f13b.png" alt="m \times m \times n"/> with <img class="math" src="_images/math/ea3f1187e773d9a683ee3a6928a6ac9b90bf45f9.png" alt="m \in \{1, 2, 4, 8 ,16, 32\}"/> and <img class="math" src="_images/math/65f362b15239bf7c2f4c7f141bc620e8aa79a891.png" alt="n \in \{128, 256, 512, 1024, 2048, 4096, 8192\}"/> using <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>. We first evaluate the effects of the different data layouts on file size (Section <a class="reference internal" href="#hdf5-test-chunking-filesize"><span>File Size</span></a>) and write performance (Section <a class="reference internal" href="#hdf5-test-chunking-write"><span>Data Write</span></a>). We then compare the performance for performing the three selection test cases (Section <a class="reference internal" href="#hdf5-test-chunking-select"><span>Selection Performance</span></a>). We conclude this chunked layout study with an evaluation of the overall performance of the different chunked data layouts to identify the best-performing data layouts (Section <a class="reference internal" href="#hdf5-test-chunking-select"><span>Selection Performance</span></a>)</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="fc1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>See also <a class="reference external" href="http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/">http://www.hdfgroup.org/HDF5/doc/Advanced/Chunking/</a></td></tr>
</tbody>
</table>
<div class="section" id="file-size">
<span id="hdf5-test-chunking-filesize"></span><h3>File Size<a class="headerlink" href="#file-size" title="Permalink to this headline">Â¶</a></h3>
<p>The use of chunking effects the size of data files in two main ways. First, storing the additional metadata required for chunking &#8212;such as the B-tree used for indexing of data chunks&#8212; increases file size. Second, the use of chunking may result in allocation of additional empty data (padding) in case that the chunks do not align with the data. This can result in substantial data overheads. A simple example illustrates this problem. When storing a simple 1D dataset with 101 elements using a chunk size of 100, then we need to allocated two chunks, one chunk to store the first 100 elements and a second chunk to store the last element. In this case we allocated space for 200 elements in order to store 101 elements, nearly twice the amount of storage needed for the raw data. For multi-dimensional data arrays &#8211;here 3D&#8211; the storage overheads due to padding can increase even faster. It is, therefore, important that we consider the potential storage overhead when evaluating the use of data chunking.</p>
<div class="figure" id="id20">
<span id="hdf5filesize-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Chunking_Filesizes.png"><img alt="File sizes using different chunk sizes in HDF5." src="_images/HDF5_Chunking_Filesizes.png" style="width: 916.3px; height: 581.0px;" /></a>
<p class="caption"><span class="caption-text">File sizes using different chunking strategies</span></p>
</div>
<p>Figure <a class="reference internal" href="#hdf5filesize-figure"><span>File sizes using different chunking strategies</span></a> illustrates the effects of chunking on the size of data files. The baseline curve indicates the file size using a contiguous data layout. We observe that the file with a chunking of <img class="math" src="_images/math/d7f5be8025ad1d45f9c82b77f99edf3b34550c72.png" alt="1 \times 1 \times 128"/> is much larger than the other files with a <img class="math" src="_images/math/4ec125816e39c87357155cc8d59fa8b9fa83f298.png" alt="1 \times 1 \times n"/> chunked layout. No padding is applied in the spatial dimensions <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/>, <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/>. When using a <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> chunk size of 128, 782 chunks are required per spectrum, resulting in a total of 7,820,000 chunks. Due to padding in the <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> dimension, 96 <img class="math" src="_images/math/c9ffd501cd5c5716536b2edc75fea900bfa62a95.png" alt="100 \times 100"/> slices remain empty. However, this accounts for only <img class="math" src="_images/math/b0f7cd16d5396927e5bb38c8db483823ddf775e0.png" alt="100*100*96*2 \text{Bytes} = 1,920,000 \text{Bytes} = 1.92 \text{MB}"/>. In comparison, the <img class="math" src="_images/math/e0e76dfae04212c4e405e67edbb8654003ba7c86.png" alt="1 \times 1 \times 2048"/> dataset is much smaller while requiring a much larger <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> padding of 352 slices (i.e, <img class="math" src="_images/math/765658f2c9d39477d0507826d859ad692e5957e1.png" alt="\approx 7.04 \text{MB}"/>). The reason for the larger file size for the <img class="math" src="_images/math/d7f5be8025ad1d45f9c82b77f99edf3b34550c72.png" alt="1 \times 1 \times 128"/> chunking illustrates the large overhead for storing the metadata required for the large number of chunks.</p>
<p>We also observe that the file size increases significantly when using chunk sizes in x, y of <img class="math" src="_images/math/d50e83eec9bd0cba376b0d2d6c4cca633a32da12.png" alt="8 \times 8 \times n"/> or larger. This behavior is due to the padding required in the spatial dimensions. For example, when using a chunking of <img class="math" src="_images/math/c5200fed2b33e82b2bb25db568a7a2c5c53b96da.png" alt="32 \times 32 \times n"/> we requires 4 chunks in the <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> and <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> dimension (i.e., <img class="math" src="_images/math/15a088b6b19a005c5e98881b9aa6fbc167f73f6f.png" alt="4*32=128"/> elements). This means, in order to store the <img class="math" src="_images/math/88b9901484e3098a9105be872600aae61460ba58.png" alt="100 \times 100 \times 100,000"/> test dataset, we allocate space for at least <img class="math" src="_images/math/6b78a848af714089eb17118146f27a7e5340af55.png" alt="128 \times 128 \times 100,000"/> records (additional padding may be required in the <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> dimension). This means that we allocate at least an additional amount of space of <img class="math" src="_images/math/a0da8a7c4238f865a3bd4ee96d63e94f70eaa0f4.png" alt="(28*128*100,000) + (28*100*100,000) \text{ records} = 638,400,000 * 2 \text{ Bytes} = 1,276,800,000 \text{ Bytes} =  1276.8 \text{ MB}"/>. This example illustrates that a bad choice for the chunking can result in substantially larger data files. Since in the case of MSI  data, the <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/>, <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> dimensions of the data are much smaller than the <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> (<img class="math" src="_images/math/3130cbd6e7d011fff87ef4990f4fdaca9c88b594.png" alt="mz"/>, mass) dimension, it is important that we keep the padding required in <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/> and <img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> as small as possible, whereas padding in the <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> dimension typically has a much smaller effect on the size of the data.</p>
</div>
<div class="section" id="data-write">
<span id="hdf5-test-chunking-write"></span><h3>Data Write<a class="headerlink" href="#data-write" title="Permalink to this headline">Â¶</a></h3>
<p>Traditionally, MSI data is often written one-spectrum-at-a-time. Figure <a class="reference internal" href="#hdf5write1-figure"><span>Write performance using one-spectrum-at-a-time I/O using different chunk sizes (hopper using /scratch)</span></a> illustrates the write performance for the different data layouts using a one-spectrum-at-a-time write strategy. It is not surprising that we observes a significant decrease in performance with increasing chunk sizes <img class="math" src="_images/math/c4bb40dd65eae6c11b325989b14e0b8d35e4e3ef.png" alt="m"/> in the x and y dimensions, as each data chunk is modified <img class="math" src="_images/math/6e27ced2d49e60d82e9313a41160ce3bf76a5885.png" alt="m*m"/> times. For chunkings of <img class="math" src="_images/math/d62bbebe25f80720e6d79e05cbaf222387c8ffe1.png" alt="m \times m \times 32"/> with <img class="math" src="_images/math/af2d21da36ae04d032ac5119fb8d4055431c3320.png" alt="m \in \{1024, 2048, 4096, 8192\}"/> the write performance improves possibly due to higher HDF5 chunk-cache hit rates. The write performance data points for data layouts with a chunking of <img class="math" src="_images/math/f524e0947e3bbf324551401e10f64f68e2e8c715.png" alt="128 \times 128 \times 32"/> , <img class="math" src="_images/math/c5a971abd2beb1946ca6a1748d656922c597a5b1.png" alt="256 \times 256 \times 32"/> , and <img class="math" src="_images/math/45060dcfc7daef99f827cd1d10507f425cbd3759.png" alt="512 \times 512 \times 32"/> are missing as we terminated the tests due to the very poor one-spectrum-at-a-time write performance in those cases.</p>
<div class="figure" id="id21">
<span id="hdf5write1-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Write_Hopper_Scratch_OneAtATime.png"><img alt="Write performance one-spectrum-at-a-time I/O and chunking (``hopper``/scratch)." src="_images/HDF5_Write_Hopper_Scratch_OneAtATime.png" style="width: 861.75px; height: 566.25px;" /></a>
<p class="caption"><span class="caption-text">Write performance using one-spectrum-at-a-time I/O using different chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<div class="figure" id="id22">
<span id="hdf5write2-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Write_Hopper_Project_Compare.png"><img alt="Write performance using different data-write strategies (``hopper using ``/project``)" src="_images/HDF5_Write_Hopper_Project_Compare.png" style="width: 797.55px; height: 504.4px;" /></a>
<p class="caption"><span class="caption-text">Write performance using different data write strategies and chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>)</span></p>
</div>
<p>To achieve optimal data write performance, it is important that we reduce the number of times each chunk is modified. Figure <a class="reference internal" href="#hdf5write2-figure"><span>Write performance using different data write strategies and chunk sizes (hopper using /project)</span></a> compares the write performance for <img class="math" src="_images/math/ac1dae7426b5491cdafe6720240976878dc6d9d7.png" alt="m \times m \times 2048"/> chunked data layout using a one-spectrum-at-a-time, <img class="math" src="_images/math/745f3493312cd221d17617b05e1ff74af67b9c1f.png" alt="m \times m"/>-spectra-at-a-time, and chunk-at-a-time data write strategy. Using the latter two strategies ensures that each chunk is modified only once. We observe that the chunk-at-a-time write strategy quickly outperforms the other write strategies as the chunk size increases (and the total number of chunks decreases). It is not surprising that the contiguous baseline layout outperforms the chunked layouts in a serial setting. However, the chunked layouts efficiently support parallel data write operations. Using a chunk-at-a-time write strategy, independent parallel tasks can be utilized to write the different chunks.</p>
</div>
<div class="section" id="selection-performance">
<span id="hdf5-test-chunking-select"></span><h3>Selection Performance<a class="headerlink" href="#selection-performance" title="Permalink to this headline">Â¶</a></h3>
<p>In this section we evaluate the selection performance of the different chunked data layouts for the three selection test cases: i) selection of a random set of 25 consecutive z-slices, ii) selection of a random <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> set of full spectra, and iii) selection of a random <img class="math" src="_images/math/4e97e145116924f9be52a57c4b6d2d3498361355.png" alt="5 \times 5 \times 1000"/> subcube of the data. Figure <a class="reference internal" href="#hdf5-chunking-slice-figure"><span>Performance results for z-slice selection using varying chunk sizes (hopper using /scratch)</span></a> <a class="footnote-reference" href="#f0" id="id2">[2]</a>  shows the results for the z-slice hyperslap selection. We observe that data layouts with a chunking of <img class="math" src="_images/math/da74985ed767098a98e4c6bae0a872ed7674f13b.png" alt="m \times m \times n"/> with <img class="math" src="_images/math/cffd61523542dff13bd11a15e024b31131a20170.png" alt="m \in \{4, 8 ,16\}"/> and <img class="math" src="_images/math/f67eb0b287635b451819a4eeafe31d61c798881f.png" alt="n \in \{128, 256, 512, 1024, 2048, 4096\}"/> show the best z-slice selection performance. For the mentioned chunking strategies we observe in general best performance for larger values in <img class="math" src="_images/math/c4bb40dd65eae6c11b325989b14e0b8d35e4e3ef.png" alt="m"/> and smaller values of <img class="math" src="_images/math/413f8a8e40062a9090d9d50b88bc7b551b314c26.png" alt="n"/>. This behavior is likely due to the reduced amount of data and number of chunks that need to be loaded to fulfill the selection of complete slices in <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/>.</p>
<div class="figure" id="id23">
<span id="hdf5-chunking-slice-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Chunking_Hopper_SliceQuery.png"><img alt="Performance results for z-slice selection using various different chunk sizes (``hopper`` using ``/scratch``)." src="_images/HDF5_Performance_Chunking_Hopper_SliceQuery.png" style="width: 789.6px; height: 617.4px;" /></a>
<p class="caption"><span class="caption-text">Performance results for z-slice selection using varying chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<div class="figure" id="id24">
<span id="hdf5-chunking-spectra-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Chunking_Hopper_SpectraQuery.png"><img alt="Performance results for spectra selection using various different chunk sizes (``hopper`` using ``/scratch``)." src="_images/HDF5_Performance_Chunking_Hopper_SpectraQuery.png" style="width: 790.3px; height: 563.5px;" /></a>
<p class="caption"><span class="caption-text">Performance results for spectra selection using varying chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<p>For the spectra selections (see Figure <a class="reference internal" href="#hdf5-chunking-spectra-figure"><span>Performance results for spectra selection using varying chunk sizes (hopper using /scratch)</span></a>) we observe in most cases a decrease in the median performance compared to the baseline contiguous data layout. This behavior is likely due to the fact that the data is flattened in a z-column order in the contiguous layout, so that a full spectrum can be read via a single seek and contiguous read operation. In contrast, using a chunked data layout requires for the test dataset, loading <img class="math" src="_images/math/bb2dbf2cb211c19b18e624a56a3f02b136a328af.png" alt="100,000 / n"/> chunks. However, we observe that data layouts with a chunk size in z of 1024 and larger, still provide good performance for the selection of full spectra. In this case, small chunk sizes in x, y of 2 or 4, work well for the test case of loading a <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> set of spectra, as the number of chunks that need to be loaded remains constant. For data layouts with a x,y chunking of <img class="math" src="_images/math/264e2f4f15d86ec2b723cd8d7f3a983c142383c7.png" alt="8 \times 8"/>, the <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> spectra selection can fit into a single x,y chunk, however, it is still likely that the <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> selection crosses multiple chunk boarders, requiring the load of a large number of chunks. For x, y chunk sizes of 16 or 32, the <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> spectra selection is more likely to fit in a single chunk in x,y, explaining the better performance of those data layouts.</p>
<div class="figure" id="id25">
<span id="hdf5-chunking-subcube-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Chunking_Hopper_SubcubeQuery.png"><img alt="Performance for 3D subcube selection using various different chunk sizes (``hopper`` using ``/scratch``)." src="_images/HDF5_Performance_Chunking_Hopper_SubcubeQuery.png" style="width: 903.0px; height: 571.9px;" /></a>
<p class="caption"><span class="caption-text">Performance results for 3D subcube selection using varying chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<p>Figure <a class="reference internal" href="#hdf5-chunking-subcube-figure"><span>Performance results for 3D subcube selection using varying chunk sizes (hopper using /scratch)</span></a> <a class="footnote-reference" href="#f0" id="id3">[2]</a> summarizes the results for the selection of a <img class="math" src="_images/math/4e97e145116924f9be52a57c4b6d2d3498361355.png" alt="5 \times 5 \times 1000"/> data subcube. We observe that using chunking generally improves the performance of the selection. In particular, using chunking decreases the time for initial data access compared to the baseline contiguous data layout.</p>
<p>When comparing the selection performance plots, we observe that &#8212; even though the amount of data that is retrieved is only 0.5MB in z-slice selection case compared to 5MB in the spectra selection case&#8212; the performance for z-slice selection case is generally lower than for the spectra selection case. The reason for this behavior is that while the z-slice selection returns less data, the number of I/O (seek) operations required and the amount of data that needs to be loaded to fulfill the selection is larger. E.g, using a chunking of <img class="math" src="_images/math/0fdd2f8668f5311f51ec444ce04b7438702f27cd.png" alt="4 \times 4 \times 2048"/> each chunk requires <img class="math" src="_images/math/ce7cbaf3086febb1a19a6e49c369aaa11aaa63f5.png" alt="4*4*2048*2 \text{Byte} = 65536 \text{Byte} = 64 \text{kB}"/>. To retrieve a <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> set of spectra, HDF5 needs to load <img class="math" src="_images/math/0a1b1dd1b82403974e5896166503a1bdbdd66284.png" alt="2*2*49 \text{ Chunks} = 196*64 \text{ kB} = 12.25 \text{ MB}"/>, whereas in order retrieve 25 z-slices (without crossing a z-chunk boundary),  HDF5 needs to load <img class="math" src="_images/math/2bb194c3cef781d71deaa4419164a3754822b7bf.png" alt="25*25 \text{ Chunks} = 625 \text{ Chunks} =  39.0625 \text{ MB}"/>, i.e, more than three times the data (and that even though the <img class="math" src="_images/math/b49e6e1277a83a8e6c40ce8c37373b89b6f6ea27.png" alt="4 \times 4"/> x,y chunking does not align well with the <img class="math" src="_images/math/e759ef2fac54b8adc2acbf1029f4a376975b31d1.png" alt="5 \times 5"/> spectra selection). Similary, in the contiguous data layout, we can load a single spectrum using a single seek and contiguous read operation, whereas in order to load complete a z-slice we requires <img class="math" src="_images/math/6e27ced2d49e60d82e9313a41160ce3bf76a5885.png" alt="m*m"/> (<img class="math" src="_images/math/d460003035582cc312b73d3c9c0d854ccca183e1.png" alt="=100*100=10,000"/> for the test data) seek and load operations.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="f0" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>)</em> Bars shown transparently indicate that the bars exceed the maximum value shown in the plot. The real value for those bars are indicated via additional text labels.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="summary">
<span id="hdf5-test-chunking-summary"></span><h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">Â¶</a></h3>
<p>To illustrate the overall performance of the different dataset layouts and to identify the &#8220;best&#8221; layouts, we define the following set of minimum performance criteria a data layout should fulfill:</p>
<blockquote>
<div><ul class="simple">
<li>The median time for the z-slice selection test case should be <code class="docutils literal"><span class="pre">&lt;0.1</span> <span class="pre">s</span></code></li>
<li>The median time for the spectra selection test case should be <code class="docutils literal"><span class="pre">&lt;0.05</span> <span class="pre">s</span></code></li>
<li>The median time for the 3D subcube selection test case should be  <code class="docutils literal"><span class="pre">&lt;0.002</span> <span class="pre">s</span></code></li>
<li>The total file size should be <code class="docutils literal"><span class="pre">&lt;</span> <span class="pre">2100</span> <span class="pre">MB</span></code> (limiting the overhead in the test case to a maximum of <img class="math" src="_images/math/cfd463ce2555b7b8b32c8b4a4512c7d0882c89c7.png" alt="\approx 200 \text{MB}"/>)</li>
<li>(We do not take the write performance results shown in Figure <a class="reference internal" href="#hdf5write1-figure"><span>Write performance using one-spectrum-at-a-time I/O using different chunk sizes (hopper using /scratch)</span></a> into account in the total score here as a chunk-at-a-time write strategy likely improve the write performance significantly)</li>
</ul>
</div></blockquote>
<p>Based on these criteria we can determine an overall performance score by evaluating how many of the criteria a particular data layout fulfills (with 4=best (passes all criteria) and 0=worst (does not pass any of the criteria)). We observe a cluster of 8 data layouts that satisfy the four performance conditions.</p>
<div class="figure" id="id26">
<span id="hdf5-chunking-perfscore-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Chunking_Hopper_PerfScore.png"><img alt="Summary performance score using various different chunk sizes (``hopper`` using ``/scratch``)." src="_images/HDF5_Performance_Chunking_Hopper_PerfScore.png" style="width: 1079.4px; height: 741.3px;" /></a>
<p class="caption"><span class="caption-text">Summary performance score using various different chunk sizes (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<p>Figure <a class="reference internal" href="#hdf5-chunking-perfscore-figure"><span>Summary performance score using various different chunk sizes (hopper using /scratch)</span></a> summarizes the performance scores for the different data layouts. Bars with the maximum score of 4 are plotted opaque whereas all other bars are plotted transparently. We observe a cluster of 8 layouts with a performance score of 4. While the overall performance score used here is simple in nature, it illustrates well which data layouts achieve overall the best performance. Overall, the performance experiments indicate that the largest z chunk size for which we observe good performance in our experiments across a large range of x/y chunk sizes is 2048. We, therefore, chose a z chunk size of 2048 for further experiments.</p>
<p>So far our experiments have focused on <code class="docutils literal"><span class="pre">hopper</span></code> using the <code class="docutils literal"><span class="pre">/scratch</span></code> file system. In order to evaluate the performance of the permanent data storage system <code class="docutils literal"><span class="pre">/project</span></code> and the web-hosting system <code class="docutils literal"><span class="pre">portal</span></code> we performed a series of follow-up tests using a fixed z-chunking of 2048 on <code class="docutils literal"><span class="pre">portal</span></code> as well as on <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code> (more details are provided in the next section). We generally observed that the <code class="docutils literal"><span class="pre">/project</span></code> file system provided better serial write performance while the overall performance for selection was not as good as for <code class="docutils literal"><span class="pre">/scratch.</span> <span class="pre">While</span> <span class="pre">the</span> <span class="pre">performance</span> <span class="pre">of</span> <span class="pre">``hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code> was still acceptable, the performance (and in particular the worst-case maximum times) were poor using <code class="docutils literal"><span class="pre">/portal</span></code> (see, e.g, Figure <a class="reference internal" href="#hdf5compslice-figure"><span>Performance results for z-slice selection (portal using compression)</span></a> shown later). We, therefore, next extended our evaluation to also include data compression as an option to possibly improve data I/O performance and storage requirements.</p>
</div>
</div>
<div class="section" id="chunking-part-2">
<span id="hdf5-test-chunking-part2"></span><h2>Chunking: Part 2<a class="headerlink" href="#chunking-part-2" title="Permalink to this headline">Â¶</a></h2>
<p>In part 1 of the chunking study we were interesting in finding chunked data layouts that provide a good compromise for all three selection use-cases. In part 2 we focus on chunked data layouts that are designed to optimize single selection operations.</p>
<div class="section" id="image-aligned-chunking">
<h3>Image-aligned Chunking<a class="headerlink" href="#image-aligned-chunking" title="Permalink to this headline">Â¶</a></h3>
<p>Figure <a class="reference internal" href="#hdf5-imagealigned-cunking-figure"><span>Comparison of the performance of the default chunking with a chunked layout that is better-aligned with the ion-images to improve the performance the z-slice selection.</span></a> shows the performance of the z-slice selection in the OpenMSI client when optimizing the chunked data layout to align with the selection of m/z images. Using an image-aligned chunking of <img class="math" src="_images/math/4d1e0d24de592b8d158a968bca4d79fcfad6591f.png" alt="50 \times 80 \times 100"/>, only 10 chunks containing 100 image slice need to be read in order to retrieve a single image slice, wheras, using the default chunking of <img class="math" src="_images/math/0fdd2f8668f5311f51ec444ce04b7438702f27cd.png" alt="4 \times 4 \times 2048"/>, HDF5 needs to load 2,520 chunks containing 2048 image slices. The figure shows the performance we achieve in the OpenMSI client using the same data stored without compression using the two different chunked layouts. Using the default chunking it takes <img class="math" src="_images/math/18950bdb7b66d395e88363f32af45568511069b1.png" alt="\approx 20s"/> to compute the ion-images compared to just <img class="math" src="_images/math/267433279593ced36834df772e8d9c17f4f417be.png" alt="\approx 0.5s"/> using the image-aligned chunking. However, not surprisingly, the performance of the orthogonal operation of selecting full spectra decreases significantly (here from 45ms to 8.1s) when optimizing the chunking to improve the selection of z-slices.</p>
<p>Further improvement in performance could be achieved by using a (m/z, x ,y) or (m/z, y, x) layout of the data rather than the commen (x, y, m/z). By transposing the image cube (making m/z the first dimension of the 3D cube) the data will be linearized on disk as <img class="math" src="_images/math/2f7cb3061f1f9b563741200d00e50bacc9ca8b8b.png" alt="{ionimage_{0}. \ ionimage_{1}, \ ... \ , \ ionimage_{n}}"/> rather than <img class="math" src="_images/math/74fd998eeb7883e7daf18ba33cb2ca9ad495b583.png" alt="{spectrum_{0,0}, \ spectrum_{0,1}, \ ... \ , \ spectrum_{l,m} }"/>. Linearizing the data in image order improves locality of data and reduces the number of seek operations required when loading ion-image. Currently, reordering of data dimensions is not yet supported by HDF5 as a transparent data layout optimization, but rather needs to be performed manually by the user. To remain ease of usability of the OpenMSI file format we, therefore, chose to use a consistent ordering of dimensions in all cases.</p>
<div class="figure" id="id27">
<span id="hdf5-imagealigned-cunking-figure"></span><a class="reference internal image-reference" href="_images/ImageAligned_Chunking_Example.png"><img alt="Comparison of the performance of the default chunking with a chunked layout that is better-aligned with the ion-images to improve the performance the z-slice selection." src="_images/ImageAligned_Chunking_Example.png" style="width: 1050.0px; height: 526.4px;" /></a>
<p class="caption"><span class="caption-text">Comparison of the performance of the default chunking with a chunked layout that is better-aligned with the ion-images to improve the performance the z-slice selection.</span></p>
</div>
</div>
</div>
<div class="section" id="compression">
<span id="hdf5-test-compress"></span><h2>Compression<a class="headerlink" href="#compression" title="Permalink to this headline">Â¶</a></h2>
<p>The primary goal of data compression is to reduce the size of data by providing a more compact encoding of the data. In many cases, compression is used as means to reduce the size of data stored on disk. However, while additional compute time overheads are incurred due to the time required for compression/decompression of the data during write/read, compression may also improve the read and/or write performance, as less data needs to be transferred and/or written to disk. This is in particular the case in I/O bound systems (e.g., due to network bottlenecks etc.).</p>
<p>Use of data compression in HDF5 relies on the use of chunking and, hence, shares the same overheads and advantages and disadvantages. Compression is applied to each chunk of the data. The overall compression ratio achieved, therefore, inherently relies on the use of a good chunking strategy. Data compression is implemented via I/O filters in HDF5, which are applied transparently during data read and write operations, i.e., after enabling compression when generating the dataset, data read/write operations are performed using the same API calls whether the data is stored in raw or compressed form.</p>
<p><code class="docutils literal"><span class="pre">HDF5/h5py</span></code> typically provides three main compression algorithms: i) <code class="docutils literal"><span class="pre">gzip</span></code>, standard <code class="docutils literal"><span class="pre">HDF5</span></code> deflate compression available with most HDF5 installations, ii) <code class="docutils literal"><span class="pre">szip</span></code>, third-party compression algorithm optionally available with HDF5 (i.e., it may not be available on all systems), iii) <code class="docutils literal"><span class="pre">LZF</span></code> is a stand-alone compression filter for HDF5 available via <code class="docutils literal"><span class="pre">h5py</span></code> but may not be available in many other standard (non-Python) installations of HDF5. In the context of OpenMSI it is important that we are able to transfer and use data at different institutes, compute systems and using a larger range of API&#8217;s for accessing HDF5 data (e.g., matlab, HDF5 C API, h5py etc.). We, therefore, chose the standard <code class="docutils literal"><span class="pre">gzip</span></code> compression filter as it is typically available with most systems (in contrast to <code class="docutils literal"><span class="pre">LZF</span></code> and <code class="docutils literal"><span class="pre">szip</span></code>). The <code class="docutils literal"><span class="pre">gzip</span></code> filter provides and additional <code class="docutils literal"><span class="pre">aggression</span></code> parameter. The <code class="docutils literal"><span class="pre">aggression</span></code> parameter is a number between <img class="math" src="_images/math/8b3aff4e274a4a9c09266e25efa40c11d1938ef4.png" alt="[0,9]"/> to indicate the trade-off between speed and compression ratio (zero is fastest, nine is best ratio). Unless indicated otherwise, we here generally set the <code class="docutils literal"><span class="pre">aggression</span></code> parameter to <img class="math" src="_images/math/51a8d7e791ab9e463af82a4075edb04ef8028dcf.png" alt="4"/> for all tests to achieve a balance of compression ratio and speed.</p>
<div class="section" id="compression-ratio">
<h3>Compression Ratio<a class="headerlink" href="#compression-ratio" title="Permalink to this headline">Â¶</a></h3>
<p>Using a chunking of <img class="math" src="_images/math/b787cb4b7e2763201b82a94e94aa57c0fada2600.png" alt="4 \times 4 \times 2,048"/>, we achieve for dataset <img class="math" src="_images/math/0acafa529182e79b4f56165ec677554fba7fcf98.png" alt="A"/> a compression ratio of <img class="math" src="_images/math/08ed9ce019da95f03bc50f76a3063dd2179cbdc9.png" alt="\approx 2.9"/>, reducing the data from 3.3GB (including <img class="math" src="_images/math/0f34e77106d2aaa3970e3d9a669ff3157f58b8c8.png" alt="\approx 100"/> MB of data for nmf and global peak-finding) to 1.2GB (while only the MSI data is stored in compressed form). Using the same setup, we achieve for dataset <img class="math" src="_images/math/83956e92fcc80dee17fce864543216939a3c9da7.png" alt="B"/> a compression ratio of <img class="math" src="_images/math/fecca42d2573d14574404c57726c45b22eae6394.png" alt="\approx 6.3"/>, reducing the dataset from 9.5GB to 1.5GB (again with nmf and global peak-finding results included in the file and stored uncompressed in both cases). An overview of the file sizes using compression and compression ratios achieved using the <img class="math" src="_images/math/88b9901484e3098a9105be872600aae61460ba58.png" alt="100 \times 100 \times 100,000"/> test dataset (using dataset <cite>A</cite> as donor MSI dataset) are summarized in Figure  <a class="reference internal" href="#hdf5compratio-figure"><span>Compression ratios using different chunk sizes</span></a>. The compression ratios we achieve are on the order of 2.9 to 3.8 in all cases (comparable to the compression ratio we have seen for the donor dataset <img class="math" src="_images/math/0acafa529182e79b4f56165ec677554fba7fcf98.png" alt="A"/>).</p>
<div class="figure" id="id28">
<span id="hdf5compratio-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_Ratio.png"><img alt="Compression ratios using different chunk sizes." src="_images/HDF5_Performance_Compression_Ratio.png" style="width: 871.47px; height: 502.32px;" /></a>
<p class="caption"><span class="caption-text">Compression ratios using different chunk sizes</span></p>
</div>
<div class="figure" id="id29">
<span id="hdf5comprealdata-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Compression_Dataset_Summary.png"><img alt="Compression performance on a select set of real MSI datasets." src="_images/HDF5_Compression_Dataset_Summary.png" style="width: 937.3px; height: 648.7px;" /></a>
<p class="caption"><span class="caption-text">Compression performance on a select set of real MSI datasets.</span></p>
</div>
</div>
<div class="section" id="id4">
<h3>Data Write<a class="headerlink" href="#id4" title="Permalink to this headline">Â¶</a></h3>
<p>Figure <a class="reference internal" href="#hdf5compwrite-figure"><span>Serial write performance using compression</span></a> compares the write performance results with and without using compression for data layouts with a chunking of <img class="math" src="_images/math/ac1dae7426b5491cdafe6720240976878dc6d9d7.png" alt="m \times m \times 2048"/> with <img class="math" src="_images/math/bd87da1d65c242f912ad2a8434703df8855dc698.png" alt="m \in [1 , 10]"/>. As expected, we observe a general decrease in the write performance when using compression. As mentioned earlier, when using compression it is important that we use a chunk-aligned data write strategy as the compression filter needs to be executed each time a chunk is loaded and/or modified. We, therefore, use the chunk-at-a-time write strategy when writing HDF5 datasets with compression enabled.</p>
<div class="figure" id="id30">
<span id="hdf5compwrite-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_Write.png"><img alt="Write performance using compression." src="_images/HDF5_Performance_Compression_Write.png" style="width: 808.5px; height: 484.4px;" /></a>
<p class="caption"><span class="caption-text">Serial write performance using compression</span></p>
</div>
</div>
<div class="section" id="id5">
<h3>Selection Performance<a class="headerlink" href="#id5" title="Permalink to this headline">Â¶</a></h3>
<p>In this section we evaluate the selection performance of the different <img class="math" src="_images/math/ac1dae7426b5491cdafe6720240976878dc6d9d7.png" alt="m \times m \times 2048"/> chunked data layouts (with <img class="math" src="_images/math/bd87da1d65c242f912ad2a8434703df8855dc698.png" alt="m \in [1 , 10]"/>) for <code class="docutils literal"><span class="pre">portal</span></code> and <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code> and <code class="docutils literal"><span class="pre">/scratch</span></code>. For <code class="docutils literal"><span class="pre">portal</span></code> we observe that using compression can significantly improve the median selection time for the z-slice selection test case (see Figure <a class="reference internal" href="#hdf5compslice-figure"><span>Performance results for z-slice selection (portal using compression)</span></a>). In particular, using compression significantly reduces and stabilizes the worst-case maximum time for selecting z-slices of the data <a class="footnote-reference" href="#f1" id="id6">[3]</a> . This is especially important in the context of a web-based application, such as, OpenMSI&#8217;s online data viewer. For the other two selection test cases we observe that we can achieve similar performance for the spectra and 3D subcube selection test cases on <code class="docutils literal"><span class="pre">portal</span></code> with and without compression (see Figures <a class="reference internal" href="#hdf5compspectra-figure"><span>Performance results for spectra selection (portal using compression)</span></a>  and <a class="reference internal" href="#hdf5compsubcube-figure"><span>Performance results for 3D subcube selection (portal using compression)</span></a>)</p>
<p>The selection performance results for <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code> and <code class="docutils literal"><span class="pre">/scratch</span></code> and with and without using compression are shown in Figures: i) <a class="reference internal" href="#hdf5comphopperslice-figure"><span>Performance results for z-slice selection (hopper using compression)</span></a> , ii) <a class="reference internal" href="#hdf5comphopperspectra-figure"><span>Performance results for spectra selection (hopper using compression)</span></a>, and <a class="reference internal" href="#hdf5comphoppersubcube-figure"><span>Performance results for subcube selection (hopper using compression)</span></a>. As baseline we use the performance of the contiguous data layout on <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>. In contrast to <code class="docutils literal"><span class="pre">portal</span></code>, we observe on <code class="docutils literal"><span class="pre">hopper</span></code> a general decrease (of up to 1 order of magnitude) in the selection performance when using compression compared to when storing the data in raw, uncompressed form. Compared to the baseline contiguous data layout we, however, still observe an improvement in many cases even when using compression. Generally it appears that the use of compression may have stronger negative effect on the selection performance when operating on the <code class="docutils literal"><span class="pre">/scratch</span></code> filesystem then when using <code class="docutils literal"><span class="pre">/project</span></code> <a class="footnote-reference" href="#f2" id="id7">[4]</a>.</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="f1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[3]</a></td><td><strong>Author comment:</strong> Depending on when the test were run we have seen significant (approximately 1 order of magnitude) differences in the median selection times on <code class="docutils literal"><span class="pre">portal</span></code>, however, the maximum  appeared to not improve between different reruns of the experiments. Using compression, the results on <code class="docutils literal"><span class="pre">portal</span></code> have been much more stable and, in particular, the maximum times were much better. This indicates that: i) system load, on a highly utilized system like <code class="docutils literal"><span class="pre">portal</span></code>, has a significant impact on the performance and ii) compression can significantly improve performance the selection performance on I/O bound systems and stabilized the performance results.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="f2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[4]</a></td><td><strong>Author comment:</strong> Note, <code class="docutils literal"><span class="pre">/scratch</span></code> is a parallel, LUSTRE-based file system, whereas <code class="docutils literal"><span class="pre">/project</span></code> is based on GPFS. Also <code class="docutils literal"><span class="pre">hopper</span></code> may have a higher bandwidth connection to the <code class="docutils literal"><span class="pre">/scratch</span></code> file system than <code class="docutils literal"><span class="pre">/project</span></code>. Overall, accesses to <code class="docutils literal"><span class="pre">/project</span></code> is likely to be more I/O bound than access to <code class="docutils literal"><span class="pre">/scratch</span></code>.</td></tr>
</tbody>
</table>
<div class="figure" id="id31">
<span id="hdf5compslice-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_SliceQuery.png"><img alt="Performance results for z-slice selection (``portal`` using compression)" src="_images/HDF5_Performance_Compression_SliceQuery.png" style="width: 959.7px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for z-slice selection (<code class="docutils literal"><span class="pre">portal</span></code> using compression)</span></p>
</div>
<div class="figure" id="id32">
<span id="hdf5compspectra-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_SpectraQuery.png"><img alt="Performance results for spectra selection (``portal`` using compression)" src="_images/HDF5_Performance_Compression_SpectraQuery.png" style="width: 990.5px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for spectra selection (<code class="docutils literal"><span class="pre">portal</span></code> using compression)</span></p>
</div>
<div class="figure" id="id33">
<span id="hdf5compsubcube-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_SubcubeQuery.png"><img alt="Performance results for 3D subcube selection (``portal`` using compression)" src="_images/HDF5_Performance_Compression_SubcubeQuery.png" style="width: 957.6px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for 3D subcube selection (<code class="docutils literal"><span class="pre">portal</span></code> using compression)</span></p>
</div>
<div class="figure" id="id34">
<span id="hdf5comphopperslice-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_hopper_SliceQuery.png"><img alt="Performance results for z-slice selection (``hopper`` using compression)" src="_images/HDF5_Performance_Compression_hopper_SliceQuery.png" style="width: 977.9px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for z-slice selection (<code class="docutils literal"><span class="pre">hopper</span></code> using compression)</span></p>
</div>
<div class="figure" id="id35">
<span id="hdf5comphopperspectra-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_hopper_SpectraQuery.png"><img alt="Performance results for spectra selection (``hopper`` using compression)" src="_images/HDF5_Performance_Compression_hopper_SpectraQuery.png" style="width: 980.0px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for spectra selection (<code class="docutils literal"><span class="pre">hopper</span></code> using compression)</span></p>
</div>
<div class="figure" id="id36">
<span id="hdf5comphoppersubcube-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Performance_Compression_hopper_SubcubeQuery.png"><img alt="Performance results for spectra selection (``hopper`` using compression)" src="_images/HDF5_Performance_Compression_hopper_SubcubeQuery.png" style="width: 980.0px; height: 585.2px;" /></a>
<p class="caption"><span class="caption-text">Performance results for subcube selection (<code class="docutils literal"><span class="pre">hopper</span></code> using compression)</span></p>
</div>
</div>
<div class="section" id="aggression-parameter-study">
<h3>Aggression Parameter Study<a class="headerlink" href="#aggression-parameter-study" title="Permalink to this headline">Â¶</a></h3>
<p>So far we have focused on the performance using <code class="docutils literal"><span class="pre">gzip</span></code> with <img class="math" src="_images/math/ddc64be5450cff8990fbde22fed70f56badcc4e5.png" alt="aggression=4"/>, assuming that a medium aggression value provides a good balance of compression ratio and speed. <a class="footnote-reference" href="#f3" id="id8">[5]</a> The goal of this section is to determine the influence of the <img class="math" src="_images/math/28a0291b09cd514d33e855bf93d067e88e6d58d1.png" alt="aggression"/> setting on the overall performance. Figure <a class="reference internal" href="#hdf5compaggrsizewrite-figure"><span>File size and write performance using varying gzip aggression settings</span></a> shows that the data compression we achieve for the test <img class="math" src="_images/math/88b9901484e3098a9105be872600aae61460ba58.png" alt="100 \times 100 \times 100,000"/> dataset (using dataset A as donor dataset) are comparable for all <img class="math" src="_images/math/2bce22e60f6dbc91bba4cd97a33f10d6c4b25d55.png" alt="aggression \in [1,8]"/> settings (we did not evaluate an aggression setting of 9 as the write performance was very poor). For the data write, we observe that the performance is acceptable for <img class="math" src="_images/math/96eef2b9151f5afd44da7c7ff618cffc67fa21c3.png" alt="aggression \in [1,5]"/> and decreases significantly for <img class="math" src="_images/math/8d6516c69c70a6d8712397100cab20b20414ca17.png" alt="aggression &gt;5"/>.</p>
<p>For the selection test cases, the performance results are consistent with the results from the previous tests. On <code class="docutils literal"><span class="pre">portal</span></code>, the performance of the z-slice selection improves significantly when using compression, while the spectra and subcube selection show comparable performance with and without compression (see Figure <a class="reference internal" href="#hdf5compaggrselectportal-figure"><span>Selection performance results using varying gzip aggression settings (portal)</span></a>). For <code class="docutils literal"><span class="pre">hopper</span></code>, we again observe a general strong decrease in the selection performance when enabling compression (while, although much slower, the overall selection performance is still acceptable) (see Figures <a class="reference internal" href="#hdf5compaggrselecthopperproj-figure"><span>Selection performance results using varying gzip aggression settings (hopper using /project)</span></a> and <a class="reference internal" href="#hdf5compaggrselecthopperscratch-figure"><span>Selection performance results using varying gzip aggression settings (hopper using /scratch)</span></a> <a class="footnote-reference" href="#f5" id="id9">[6]</a>).</p>
<p>Overall, we find that for the data layouts tested here, increasing the aggression parameter above 1 does not have a large impact on the compression ratio and selection performance, whereas high aggression values may significantly decrease the data write performance. In the context of MSI data, low aggression values of <img class="math" src="_images/math/b0b79dc73781caffb50745b26c45cd17d929f4b5.png" alt="aggression \in [1,4]"/> may, therefore, be preferable when using <code class="docutils literal"><span class="pre">gzip</span></code> compression.</p>
<div class="figure" id="id37">
<span id="hdf5compaggrsizewrite-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Compression_Aggression_FileSize_Write.png"><img alt="File size and write performance using varying ``gzip`` aggression settings" src="_images/HDF5_Compression_Aggression_FileSize_Write.png" style="width: 808.5px; height: 548.1px;" /></a>
<p class="caption"><span class="caption-text">File size and write performance using varying <code class="docutils literal"><span class="pre">gzip</span></code> aggression settings</span></p>
</div>
<div class="figure" id="id38">
<span id="hdf5compaggrselectportal-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Compression_Aggression_Select_Portal.png"><img alt="Selection performance results using varying ``gzip`` aggression settings (``portal``)" src="_images/HDF5_Compression_Aggression_Select_Portal.png" style="width: 737.1px; height: 545.3px;" /></a>
<p class="caption"><span class="caption-text">Selection performance results using varying <code class="docutils literal"><span class="pre">gzip</span></code> aggression settings (<code class="docutils literal"><span class="pre">portal</span></code>)</span></p>
</div>
<div class="figure" id="id39">
<span id="hdf5compaggrselecthopperproj-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Compression_Aggression_Select_hopper_project.png"><img alt="Selection performance results using varying ``gzip`` aggression settings (``hopper`` using ``project``)" src="_images/HDF5_Compression_Aggression_Select_hopper_project.png" style="width: 736.4px; height: 544.6px;" /></a>
<p class="caption"><span class="caption-text">Selection performance results using varying <code class="docutils literal"><span class="pre">gzip</span></code> aggression settings (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>)</span></p>
</div>
<div class="figure" id="id40">
<span id="hdf5compaggrselecthopperscratch-figure"></span><a class="reference internal image-reference" href="_images/HDF5_Compression_Aggression_Select_hopper_scratch.png"><img alt="Selection performance results using varying ``gzip`` aggression settings (``hopper`` using ``scratch``)" src="_images/HDF5_Compression_Aggression_Select_hopper_scratch.png" style="width: 737.1px; height: 545.3px;" /></a>
<p class="caption"><span class="caption-text">Selection performance results using varying <code class="docutils literal"><span class="pre">gzip</span></code> aggression settings (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/scratch</span></code>)</span></p>
</div>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="f3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8">[5]</a></td><td>The <img class="math" src="_images/math/28a0291b09cd514d33e855bf93d067e88e6d58d1.png" alt="aggression"/> parameter is a number between <img class="math" src="_images/math/8b3aff4e274a4a9c09266e25efa40c11d1938ef4.png" alt="[0,9]"/> to indicate the tradeoff between speed and compression ratio (0=fastest, 9=best ratio).</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="f5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9">[6]</a></td><td>Bars shown transparently indicate that the bars exceed the maximum value shown in the plot. The real value for those bars are indicated via additional text labels.</td></tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="local-scalability-multi-processing">
<h2>Local Scalability: Multi-processing<a class="headerlink" href="#local-scalability-multi-processing" title="Permalink to this headline">Â¶</a></h2>
<p>Next we tested the local scalability using Python&#8217;s multiprocessing capabilities (i.e, on a single <code class="docutils literal"><span class="pre">hopper</span></code> login node and <code class="docutils literal"><span class="pre">portal</span></code>, and not across multiple compute nodes). We again use a <img class="math" src="_images/math/88b9901484e3098a9105be872600aae61460ba58.png" alt="100 \times 100 \times 100,000"/> test dataset (using <cite>A</cite> as donor dataset) and we regenerate the dataset for each experiment (i.e., file layout + system). We repeat each computation 50 times on the same file and report the average times and standard deviations. For this test we select 20,000 z slices (i.e, 20% of the data) and compute the variance of the data values across the slices, i.e.:</p>
<blockquote>
<div><ul class="simple">
<li><img class="math" src="_images/math/5b6be9f10831dd67a63c6fabad4db3dda6c56732.png" alt="numpy.var( data[:,:, zstart:(zstart+20001) ] )"/> with <img class="math" src="_images/math/400774e17fbdc4fd17ba5e77ac1aa7169c8ae8e8.png" alt="zstart"/> being selected randomly (<img class="math" src="_images/math/17729d99e5b85a262fddce0a4791a17c9998590f.png" alt="zstart \in [0 , 79999]"/>)</li>
</ul>
</div></blockquote>
<p>We parallelize the computation across processes by dividing data along the x axis, i.e., each process computes for its portion of the data:</p>
<blockquote>
<div><ul class="simple">
<li><img class="math" src="_images/math/0f6e9e94cb392d85eb8f1c02c109d0f3f7b44203.png" alt="numpy.var( data[xstart:xend ,:, zstart:(zstart+20001) ] )"/></li>
</ul>
</div></blockquote>
<p>while <img class="math" src="_images/math/e0a02064791126623f713c004fbeee216a3edce3.png" alt="xstart"/> and <img class="math" src="_images/math/6bd5436e6f6e3568ec00625488e470082d02db98.png" alt="xend"/> are determined based on the process id. The result is then stored in a shared array. The average performance (with error bars indicating the standard deviation) for performing this calculation on <code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">project</span></code> are shown in Figure <a class="reference internal" href="#hdf5scaling1-hopper-project-figure"><span>Scaling results for computing the variance for 20000 z-slices (hopper using /project)</span></a>. We compute the speed-up by using the time required using 1 process as reference (i.e., the time from the current experiment so that the speed-up using 1 processor is always equal to 1)(see Figure <a class="reference internal" href="#hdf5speedup1-hopper-project-figure"><span>Speed-up results for computing the variance for 20000 z-slices (hopper using /project)</span></a>). We repeated the same tests also on <code class="docutils literal"><span class="pre">portal</span></code> (again using the <code class="docutils literal"><span class="pre">/project</span></code> file systems). The results for portal are shown in Figures: i) <a class="reference internal" href="#hdf5scaling1-portal-figure"><span>Scaling results for computing the variance for 20000 z-slices (portal)</span></a> and ii) <a class="reference internal" href="#hdf5speedup1-portal-figure"><span>Speed-up results for computing the variance for 20000 z-slices (portal)</span></a>.</p>
<p>The main bottleneck in this calculation is again the data selection/load. We observe that we can achieve good speed-up for larger numbers of processes using <code class="docutils literal"><span class="pre">hopper</span></code> compared to <code class="docutils literal"><span class="pre">portal</span></code>. This behavior is likely due to the better I/O (network) performance of <code class="docutils literal"><span class="pre">hopper</span></code> compared to <code class="docutils literal"><span class="pre">portal</span></code>. On <code class="docutils literal"><span class="pre">portal</span></code> we observe a stable speed-up for up to 5 processes (when using compression) and we achieve a <img class="math" src="_images/math/d89058ebd5c784e7caffe2d489bd9ea7226671aa.png" alt="\approx 3 \times"/> speed-up. Using <code class="docutils literal"><span class="pre">hopper</span></code> we observe a linear speed-up for up to 8 processes. Afterwards, we still observe speed-up, however, at a lower and less stable rate. As before, we observe that using compression yields better performance on <code class="docutils literal"><span class="pre">portal</span></code> while reducing the performance when using <code class="docutils literal"><span class="pre">hopper</span></code>.</p>
<p>In the context of the OpenMSI web-based data viewer we typically need to extract smaller subsets of the data. We, therefore, next repeated the variance computation for 25 consecutive z slices (similar to the z slice selection use-case used in the previous sections). The timings and speed-up results on <code class="docutils literal"><span class="pre">portal</span></code> using default setup &#8212;i.e., with <img class="math" src="_images/math/0fdd2f8668f5311f51ec444ce04b7438702f27cd.png" alt="4 \times 4 \times 2048"/> chunking and <code class="docutils literal"><span class="pre">gzip</span></code> compression, aggression=4&#8212; are shown in Figure <a class="reference internal" href="#hdf5timingsspeedup2-portal-figure"><span>Timings and sppeed-up results for computing the variance for 25 z-slices (portal)</span></a>. We observe that even-though the amount of data retrieved is with 0.5MB comparably small &#8212;note the data being loaded to fulfill the query is on the order of 39.0625MB&#8212;, we can still achieve good speed-ups until 4-7 processes, afterwards the performance degrades again.</p>
<div class="figure" id="id41">
<span id="hdf5scaling1-hopper-project-figure"></span><a class="reference internal image-reference" href="_images/HDF5_localScaling_var_20000slices_hopper_project.png"><img alt="Scaling results for computing the variance for 20000 z-slices (``hopper`` using ``/project``)" src="_images/HDF5_localScaling_var_20000slices_hopper_project.png" style="width: 792.35px; height: 509.6px;" /></a>
<p class="caption"><span class="caption-text">Scaling results for computing the variance for 20000 z-slices (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>)</span></p>
</div>
<div class="figure" id="id42">
<span id="hdf5speedup1-hopper-project-figure"></span><a class="reference internal image-reference" href="_images/HDF5_localScaling_speedup_var_20000slices_hopper_project.png"><img alt="Speed-up results for computing the variance for 20000 z-slices (``hopper`` using ``/project``)" src="_images/HDF5_localScaling_speedup_var_20000slices_hopper_project.png" style="width: 793.0px; height: 509.6px;" /></a>
<p class="caption"><span class="caption-text">Speed-up results for computing the variance for 20000 z-slices (<code class="docutils literal"><span class="pre">hopper</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>)</span></p>
</div>
<div class="figure" id="id43">
<span id="hdf5scaling1-portal-figure"></span><a class="reference internal image-reference" href="_images/HDF5_localScaling_var_20000slices_portal.png"><img alt="Scaling results for computing the variance for 20000 z-slices (``portal``)" src="_images/HDF5_localScaling_var_20000slices_portal.png" style="width: 792.35px; height: 509.6px;" /></a>
<p class="caption"><span class="caption-text">Scaling results for computing the variance for 20000 z-slices (<code class="docutils literal"><span class="pre">portal</span></code>)</span></p>
</div>
<div class="figure" id="id44">
<span id="hdf5speedup1-portal-figure"></span><a class="reference internal image-reference" href="_images/HDF5_localScaling_speedup_var_20000slices_portal.png"><img alt="Speed-up results for computing the variance for 20000 z-slices (``portal``)" src="_images/HDF5_localScaling_speedup_var_20000slices_portal.png" style="width: 792.35px; height: 509.6px;" /></a>
<p class="caption"><span class="caption-text">Speed-up results for computing the variance for 20000 z-slices (<code class="docutils literal"><span class="pre">portal</span></code>)</span></p>
</div>
<div class="figure" id="id45">
<span id="hdf5timingsspeedup2-portal-figure"></span><a class="reference internal image-reference" href="_images/HDF5_localScaling_var_25slices_portal.png"><img alt="Timings and speed-up results for computing the variance for 25 z-slices (``portal``)" src="_images/HDF5_localScaling_var_25slices_portal.png" style="width: 654.55px; height: 501.8px;" /></a>
<p class="caption"><span class="caption-text">Timings and sppeed-up results for computing the variance for 25 z-slices (<code class="docutils literal"><span class="pre">portal</span></code>)</span></p>
</div>
</div>
<div class="section" id="discussion">
<span id="hdf5-test-discussion"></span><h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="data-layout">
<h3>Data Layout<a class="headerlink" href="#data-layout" title="Permalink to this headline">Â¶</a></h3>
<p>Use of chunking has many benefits but choosing the correct chunk size can be complicated. In the context of MSI data, the choice of a good data layout is complicated by: i) the large difference between the size of the spatial <img class="math" src="_images/math/188c175aac0a8a9c22499336711b5d7256407254.png" alt="x"/>/<img class="math" src="_images/math/b124ff74afb0914bb434e8fb849eb56d734412f8.png" alt="y"/> and the <img class="math" src="_images/math/84d7271dd9e78c1e05d6c3c6ecb60309ef7dfc73.png" alt="z"/> (<img class="math" src="_images/math/3130cbd6e7d011fff87ef4990f4fdaca9c88b594.png" alt="mz"/>, mass) dimension and ii) the need for regularly performing orthogonal data selection operations (namely selection of spectra <code class="docutils literal"><span class="pre">[x,y,:]</span></code> and full slices in z <code class="docutils literal"><span class="pre">[:,:,z]</span></code>. Our experiments have shown that a chunking of <img class="math" src="_images/math/0fdd2f8668f5311f51ec444ce04b7438702f27cd.png" alt="4 \times 4 \times 2048"/> may work well for most cases, i.e., it provides a good compromise in performance between the different selection operations while maintaining acceptable write performance and limiting the worst-case overhead in file size.</p>
<p>Our experiments have also shown that MSI data lends itself well to compression (we have seen reductions in file size on the order of <img class="math" src="_images/math/10e6a7f2658480ab97aa03d439484e4f0f8f11d2.png" alt="3 \times"/> to <img class="math" src="_images/math/ef6aa82efb91a1f0f56a8bfebd4ce8373c9612d0.png" alt="9 \times"/> on real MSI datasets). We have also seen that the use of data compression (here <code class="docutils literal"><span class="pre">gzip</span></code>) may also improve the selection performance by reducing the amount of data that needs to be loaded from disk (see results from <code class="docutils literal"><span class="pre">portal</span></code>). This is particularly true for I/O (and or network) bound systems, such as <code class="docutils literal"><span class="pre">portal</span></code>. However, we have also seen (on <code class="docutils literal"><span class="pre">hopper</span></code>) that the use of compression can also decrease the selection performance due to the time required for decompression (see results <code class="docutils literal"><span class="pre">hopper</span></code>). Having direct access to uncompressed data may, hence, be advantageous for any analyses that require a large number of random accesses to the data from a high-performance compute systems (such as <code class="docutils literal"><span class="pre">hopper</span></code>) where the time required for decompression is larger than the time saved for data transfer. However, the reduced storage requirements and overall more stable selection performance results suggest that the use of compression may be advantageous.</p>
<p>Based on the results from this study we currently use a data layout of <img class="math" src="_images/math/0fdd2f8668f5311f51ec444ce04b7438702f27cd.png" alt="4 \times 4 \times 2048"/> with <code class="docutils literal"><span class="pre">gzip</span></code> compression and <code class="docutils literal"><span class="pre">aggression=4</span></code> as default for storing MSI data using the OMSI HDF5 data format.</p>
</div>
<div class="section" id="system-performance">
<h3>System Performance<a class="headerlink" href="#system-performance" title="Permalink to this headline">Â¶</a></h3>
<p>In a serial setting we observe that <code class="docutils literal"><span class="pre">hopper</span></code>&#8216;s <code class="docutils literal"><span class="pre">/scratch</span></code> filesystem generally provides better selective read performance than the <code class="docutils literal"><span class="pre">/project</span></code> file system. This is not unexpected and overall the performance of both file systems appears to be sufficient to perform most common MSI analysis tasks. However, based on the test results it appears that on <code class="docutils literal"><span class="pre">portal</span></code>: i) the selection performance is highly dependent on system load (which appeared to be high on many occasions) and ii) the selection performance is bound by the performance of the I/O system. Since the performance using <code class="docutils literal"><span class="pre">/project</span></code> is significantly higher on <code class="docutils literal"><span class="pre">hopper</span></code> login nodes than on <code class="docutils literal"><span class="pre">portal</span></code>, it appears that the bandwidth of the network connection of <code class="docutils literal"><span class="pre">portal</span></code> to the GPFS <code class="docutils literal"><span class="pre">/project</span></code> file system may be too low to ensure a reliably fast operation of web-applications that require repeated access to large datasets. This, however, is essential for production use of science gateways that aim to make advanced data viewing and analysis capabilities accessible to the application community (such as the OpenMSI science gateway for MSI data). While we were able to achieve usable I/O performance on <code class="docutils literal"><span class="pre">portal</span></code> through the use of chunking and compression, we have also seen that even from <code class="docutils literal"><span class="pre">/project</span></code> we can achieve significantly better performance on <code class="docutils literal"><span class="pre">hopper</span></code> when storing the data in a raw, uncompressed form (i.e., we should be able to get much better selective I/O performance on <code class="docutils literal"><span class="pre">portal</span></code> using <code class="docutils literal"><span class="pre">/project</span></code>). While <code class="docutils literal"><span class="pre">portal</span></code> provides a good platform for development of science gateways and web applications, the question remains whether <code class="docutils literal"><span class="pre">portal</span></code> is powerful enough &#8212;with respect to both compute, I/O and network performance&#8212; to provide a reliable, high-performance platform for hosting production science gateways.</p>
</div>
<div class="section" id="future-work">
<h3>Future Work<a class="headerlink" href="#future-work" title="Permalink to this headline">Â¶</a></h3>
<p>In future we plan to evaluate the performance of the different data layouts in a: i) local parallel (multi-processing) and ii) distribution parallel (MPI) environment.</p>
<p>While <code class="docutils literal"><span class="pre">gzip</span></code> is one of the most widely available compression algorithms in HDF5 it is not necessarily one with the best performance. In future we plan to evaluate the use of other compression algorithms &#8212;such as, szip <a class="footnote-reference" href="#fd1" id="id10">[7]</a>, LZF <a class="footnote-reference" href="#fd2" id="id11">[8]</a>, HDF5 N-Bit Filter <a class="footnote-reference" href="#fd3" id="id12">[9]</a> , HDF5 Scale+Offset Filter <a class="footnote-reference" href="#fd4" id="id13">[10]</a> etc.&#8212; to further improve the overall read performance and to reduce the larger overheads for compression we have seen on <code class="docutils literal"><span class="pre">hopper</span></code>. In addition to compression, HDF5 also provides a shuffle filter <a class="footnote-reference" href="#fd5" id="id14">[11]</a> which can potentially further improve the effectiveness of data compression <a class="footnote-reference" href="#fd6" id="id15">[12]</a> .</p>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="fd1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[7]</a></td><td><a class="reference external" href="http://www.hdfgroup.org/doc_resource/SZIP/">http://www.hdfgroup.org/doc_resource/SZIP/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fd2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id11">[8]</a></td><td><a class="reference external" href="http://h5py.alfven.org/lzf/">http://h5py.alfven.org/lzf/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fd3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[9]</a></td><td><a class="reference external" href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetNbit">http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetNbit</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fd4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id13">[10]</a></td><td><a class="reference external" href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetScaleoffset">http://www.hdfgroup.org/HDF5/doc/RM/RM_H5P.html#Property-SetScaleoffset</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fd5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id14">[11]</a></td><td><a class="reference external" href="http://www.hdfgroup.org/HDF5/doc/RM/RM_H5Z.html">http://www.hdfgroup.org/HDF5/doc/RM/RM_H5Z.html</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="fd6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id15">[12]</a></td><td><a class="reference external" href="http://www.hdfgroup.org/HDF5/doc_resource/H5Shuffle_Perf.pdf">http://www.hdfgroup.org/HDF5/doc_resource/H5Shuffle_Perf.pdf</a> ,</td></tr>
</tbody>
</table>
</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="omsi.html" class="btn btn-neutral float-right" title="omsi Package">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="HDF5_format.html" class="btn btn-neutral" title="OMSI Data Format"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Oliver RÃ¼bel and Ben Bowen.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'devel',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>